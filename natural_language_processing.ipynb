{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0288a8af",
   "metadata": {},
   "source": [
    "# Natural Language Processing of Books Using Python\n",
    "The book title is Miracle in The Andes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37dcc94",
   "metadata": {},
   "source": [
    "## Load the book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c940b82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee4e3b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file.read() returns the entire content as a single string\n",
    "# file.readlines() returns a list of strings\n",
    "with open(\"miracle_in_the_andes.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    book = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c41ccd2",
   "metadata": {},
   "source": [
    "## How many chapters?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e30ab58",
   "metadata": {},
   "source": [
    "### With strings method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6f1e6b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book.count(\"Chapter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e6e810",
   "metadata": {},
   "source": [
    "- Actually in this book, there are only 10 chapters, but with string method the count is 11. It happens because, there are word chapter inside the paragraphs. So, that's why we need Regex to count specific pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49a8ed7",
   "metadata": {},
   "source": [
    "### With Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a3791cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7de40716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chapter 1',\n",
       " 'Chapter 2',\n",
       " 'Chapter 3',\n",
       " 'Chapter 4',\n",
       " 'Chapter 5',\n",
       " 'Chapter 6',\n",
       " 'Chapter 7',\n",
       " 'Chapter 8',\n",
       " 'Chapter 9',\n",
       " 'Chapter 1']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#single digit capture\n",
    "pattern = re.compile(\"Chapter [0-9]\")\n",
    "re.findall(pattern, book)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf5a3ab",
   "metadata": {},
   "source": [
    "There are 10 chapter, but unfortunately Chapter 10 displayed with chapter 1. It happens because (\"Chapter [0-9]\") only chapter 1 digit, so we need to add +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fc45e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chapter 1',\n",
       " 'Chapter 2',\n",
       " 'Chapter 3',\n",
       " 'Chapter 4',\n",
       " 'Chapter 5',\n",
       " 'Chapter 6',\n",
       " 'Chapter 7',\n",
       " 'Chapter 8',\n",
       " 'Chapter 9',\n",
       " 'Chapter 10']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#multiple digit capture\n",
    "pattern = re.compile(\"Chapter [0-9]+\")\n",
    "findings = re.findall(pattern, book)\n",
    "findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfe4ad65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(findings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b723f278",
   "metadata": {},
   "source": [
    "The result already right, there are 10 chapters in this book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc3de8da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if we find chapter pattern alphabetical\n",
    "pattern = re.compile(\"Chapter [a-z]+\")\n",
    "findings = re.findall(pattern, book)\n",
    "len(findings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5135eb",
   "metadata": {},
   "source": [
    "## Which are the sentences where \"love\" was used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4affbce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['love', 'love', 'love', 'love', 'love']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if we find pattern only word 'love'\n",
    "pattern = re.compile(\"love\")\n",
    "findings = re.findall(pattern, book)\n",
    "findings[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6a93d46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['passionate love for',\n",
       " 'a love of',\n",
       " 'to love the',\n",
       " 'in love with',\n",
       " 'the love and']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#[a-zA-Z] = start or end with alphabet\n",
    "#* = 0 or more letters after the space\n",
    "pattern = re.compile(\"[a-zA-Z]* love [a-zA-Z]*\")\n",
    "findings= re.findall(pattern, book)\n",
    "findings[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3dd22a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' As a young man, of course, I could not put these things into words, but I knew, and my teammates knew, that there was something special about the game, and under the guidance of the Christian Brothers we developed a passionate love for the sport that shaped our friendships and our lives.',\n",
       " ' Guido and I grew up together, playing soccer and sharing a love of motorcycles, cars, and auto racing.',\n",
       " ' Under the guidance of the Christian Brothers, both of us grew to love the game of rugby with a consuming passion.',\n",
       " ' That rowdiness came to an abrupt end for Guido in 1969, when he met and fell in love with the beautiful daughter of a Chilean diplomat.',\n",
       " ' I believe he had a great hunger for the love and comforts of a family that was happy and whole.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#[^.]* = negation point(.) ==> select all except (.)\n",
    "pattern = re.compile(\"[^.]* love [^.]*.\")\n",
    "findings= re.findall(pattern, book)\n",
    "findings[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c735a3e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(findings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2eda673",
   "metadata": {},
   "source": [
    "- With negation method, we could select all letters before or after \"love\" except point (.) But there are lackness where possibililty pattern \"love,\" couldn't be detect, because  ([^.]* love) there are space after *\n",
    "- The solution not input space in pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29c1c28c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [^.]* = select all letters except point (.)\n",
    "# [^a-zA-Z]+ = select multiple alphabet, because [^a-zA-Z] only select one alphabet\n",
    "# . = select point for the end, because it marks the end of the paragraph\n",
    "pattern =  re.compile(\"[^.]*[^a-zA-Z]+love[^a-zA-Z]+[^.]*.\")\n",
    "findings= re.findall(pattern, book)\n",
    "len(findings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696a6a1f",
   "metadata": {},
   "source": [
    "See the findings is more than the pattern before (\"[^.]* love [^.]*.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "972b9db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start the sentence with capital letter 1 times\n",
    "pattern =  re.compile(\"[A-Z]{1}[^.]*[^a-zA-Z]+love[^a-zA-Z]+[^.]*.\")\n",
    "findings= re.findall(pattern, book)\n",
    "len(findings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93d11e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['As a young man, of course, I could not put these things into words, but I knew, and my teammates knew, that there was something special about the game, and under the guidance of the Christian Brothers we developed a passionate love for the sport that shaped our friendships and our lives.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findings[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6060c537",
   "metadata": {},
   "source": [
    "## Most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1aa1cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C', 'h', 'a', 'p', 't']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if we find 1 single letter\n",
    "pattern = re.compile(\"[a-zA-Z]\")\n",
    "findings= re.findall(pattern, book)\n",
    "findings[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f9403f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chapter', 'before', 'it', 'was', 'friday']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if we select multiple letters\n",
    "pattern = re.compile(\"[a-zA-Z]+\")\n",
    "findings= re.findall(pattern, book.lower())\n",
    "findings[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b24a522c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86798"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(findings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a3159fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute frequency each words\n",
    "# example 'chapter' in d.keys, it will count, and +1 for next loop until sum total each words\n",
    "d = {}\n",
    "for word in findings:\n",
    "    if word in d.keys():\n",
    "        d[word] = d[word] + 1\n",
    "    else:\n",
    "        d[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c563fc8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5346, 'the'), (2795, 'and'), (2729, 'i'), (2400, 'to')]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort descending\n",
    "# the reason value first, because if we put key first, it will be sorted alphabetically\n",
    "d_list = [(value, key) for (key,value) in d.items()]\n",
    "d_list = sorted(d_list, reverse=True)\n",
    "d_list[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e87fe1",
   "metadata": {},
   "source": [
    "- The **most common words** used is **'the'** with 5346 frequency.\n",
    "- Actually 'the' is **stop-words** in Natural Language Processing.\n",
    "- Stop words usually ignored, because we want to get **actual words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "552247d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('was', 1430), ('it', 800), ('chapter', 11), ('before', 93)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if we put (key, value), not (value, key)\n",
    "d_list = [(key,value) for (key,value) in d.items()]\n",
    "sorted(d_list[:4], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c32e44",
   "metadata": {},
   "source": [
    "It will be sorted alphabetically, not the most common words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff8d28a",
   "metadata": {},
   "source": [
    "## Extract the paragraphs where \"love\" was used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e8213c5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['To me, this is the essence of rugby. No other sport gives you such an intense sense of selflessness and unified purpose. I believe this is why rugby players all over the world feel such a passion for the game and such a feeling of brotherhood. As a young man, of course, I could not put these things into words, but I knew, and my teammates knew, that there was something special about the game, and under the guidance of the Christian Brothers we developed a passionate love for the sport that shaped our friendships and our lives. For eight years we played our hearts out for the Christian Brothers—a brotherhood of young boys with Latin names, playing a game with deep Anglo roots under Uruguay’s sunny skies, and proudly wearing the bright green shamrock on our uniforms. The game became so much a part of our lives, in fact, that when we graduated from Stella Maris at the age of sixteen, many of us could not bear the thought that our playing days were over. Our salvation came in the form of the Old Christians Club, a private rugby team formed in 1965 by previous alumni of the Stella Maris rugby program to give Stella Maris ruggers a chance to continue playing the game after our school years ended.']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#[^\\n]+ = negation breaklines => select everything except breaklines\n",
    "pattern = re.compile(\"[^\\n]+love[^\\n]+\")\n",
    "findings = re.findall(pattern, book)\n",
    "findings[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5ad3ec",
   "metadata": {},
   "source": [
    "## Extract the chapter titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe2e362",
   "metadata": {},
   "source": [
    "### Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8ce512e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Before', 'Precious', 'Promise', 'More', 'Abandoned']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#on dataset after the title, there are 2 breaklines\n",
    "#(\"[a-zA-Z]+\\n\\n\") = breaklines included in result findings\n",
    "pattern = re.compile(\"[a-zA-Z]+\\n\\n\")\n",
    "findings = re.findall(pattern, book)\n",
    "\n",
    "#strip breaklines\n",
    "findings = [item.strip(\"\\n\\n\") for item in findings]\n",
    "findings[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8bec9a",
   "metadata": {},
   "source": [
    "### Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "33838c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Before', 'Precious', 'Promise', 'More', 'Abandoned']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(\"([a-zA-Z]+)\\n\\n\") = breaklines only included in pattern, but not included in result\n",
    "pattern = re.compile(\"([a-zA-Z]+)\\n\\n\")\n",
    "findings = re.findall(pattern, book)\n",
    "findings[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e4ebaa",
   "metadata": {},
   "source": [
    "## Function that finds the occurence of any word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "31e5250f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Before', 'Precious', 'Promise', 'More', 'Abandoned', 'Tomb', 'East', 'Death', 'Man', 'After']\n"
     ]
    }
   ],
   "source": [
    "def find(w):\n",
    "    pattern = re.compile(\"[a-zA-Z]+\")\n",
    "    findings = re.findall(pattern, book)\n",
    "    \n",
    "    d = {}\n",
    "    for word in findings:\n",
    "        if word in d.keys():\n",
    "            d[word] = d[word] + 1\n",
    "        else:\n",
    "            d[word] = 1\n",
    "    try :\n",
    "        return d[w]\n",
    "    except :\n",
    "        return f'The book does not contain the word \"{w}\"'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e719ce",
   "metadata": {},
   "source": [
    "### Call the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dabb34cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5013"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find('the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "459e430e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The book does not contain the word \"hate\"'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find('hate')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34a0e74",
   "metadata": {},
   "source": [
    "## The most used words (non-articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "24f62b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.11.4'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# python version\n",
    "from platform import python_version\n",
    "python_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1f50c044",
   "metadata": {},
   "outputs": [],
   "source": [
    "#library nltk\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b73342fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# english stopwords\n",
    "from nltk.corpus import stopwords\n",
    "english_stopwords = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e65863a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_stopwords[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "07b6bbbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5346, 'the'), (2795, 'and'), (2729, 'i'), (2400, 'to'), (2060, 'of')]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "06f7c230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select non stopwords\n",
    "filtered_words = []\n",
    "\n",
    "for count, word in d_list:\n",
    "    if word not in english_stopwords:\n",
    "        filtered_words.append((count, word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ce2ead96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(575, 'would'), (519, 'us'), (292, 'said'), (284, 'roberto'), (252, 'could')]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_words[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ce41af",
   "metadata": {},
   "source": [
    "The most used words (non-articles) is 'would' with 575 times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02be1ee7",
   "metadata": {},
   "source": [
    "## Sentiment Analysis : What is the most positive and the most negative chapter?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeec9134",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "877e3325",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ee5a3540",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "df53f73d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_amplify_ep',\n",
       " '_amplify_qm',\n",
       " '_but_check',\n",
       " '_idioms_check',\n",
       " '_least_check',\n",
       " '_never_check',\n",
       " '_punctuation_emphasis',\n",
       " '_sift_sentiment_scores',\n",
       " 'constants',\n",
       " 'lexicon',\n",
       " 'lexicon_file',\n",
       " 'make_lex_dict',\n",
       " 'polarity_scores',\n",
       " 'score_valence',\n",
       " 'sentiment_valence']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find directory of SentimentIntensityAnalyzer()\n",
    "dir(analyzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bf78db06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.545, 'pos': 0.455, 'compound': 0.8176}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use polarity_scores\n",
    "analyzer.polarity_scores(\"Hey, look how fun the movie is. I love the main characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "736c87f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.444, 'neu': 0.556, 'pos': 0.0, 'compound': -0.802}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use polarity_scores\n",
    "scores = analyzer.polarity_scores(\"Hey, look how bad the movie is. I hate the main characters\")\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647df819",
   "metadata": {},
   "source": [
    "- neg = negativity ==> range (0 to 1)\n",
    "- neu = neutrality ==> range (0 to 1)\n",
    "- pos = positivity ==> range (0 to 1)\n",
    "- compound = compound coefficient ==> range (-1 to 1)\n",
    "- compound >0 ==> more positivity\n",
    "- compound <0 ==> more negativity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c8c6f6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is a negative text\n"
     ]
    }
   ],
   "source": [
    "if scores['pos'] > scores['neg']:\n",
    "    print(\"It is a positive text\")\n",
    "else:\n",
    "    print(\"It is a negative text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0ab64d",
   "metadata": {},
   "source": [
    "### Chapters sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "84deee19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.116, 'neu': 0.76, 'pos': 0.125, 'compound': 1.0}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentiment analysis for 1 book\n",
    "analyzer.polarity_scores(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f7172a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "re.compile(r'Chapter [0-9]+', re.UNICODE)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select chapter from book\n",
    "pattern = re.compile(\"Chapter [0-9]+\")\n",
    "pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3099e6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split pattern chapter from book\n",
    "chapters = re.split(pattern, book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a322bab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In chapter there is '' empty string\n",
    "# we need to get rid of them\n",
    "len(chapters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4535e3",
   "metadata": {},
   "source": [
    "See the chapters actually 10, but because there is empty string (''), so the total is gonna be 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "35cd213f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all except empty string\n",
    "chapters = chapters[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7451b688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 {'neg': 0.061, 'neu': 0.779, 'pos': 0.16, 'compound': 1.0}\n",
      "2 {'neg': 0.12, 'neu': 0.726, 'pos': 0.154, 'compound': 0.9991}\n",
      "3 {'neg': 0.145, 'neu': 0.751, 'pos': 0.105, 'compound': -0.9999}\n",
      "4 {'neg': 0.141, 'neu': 0.721, 'pos': 0.138, 'compound': -0.9963}\n",
      "5 {'neg': 0.118, 'neu': 0.742, 'pos': 0.141, 'compound': 0.9997}\n",
      "6 {'neg': 0.124, 'neu': 0.761, 'pos': 0.115, 'compound': -0.9979}\n",
      "7 {'neg': 0.136, 'neu': 0.761, 'pos': 0.103, 'compound': -0.9999}\n",
      "8 {'neg': 0.12, 'neu': 0.786, 'pos': 0.094, 'compound': -0.9998}\n",
      "9 {'neg': 0.097, 'neu': 0.824, 'pos': 0.079, 'compound': -0.9996}\n",
      "10 {'neg': 0.086, 'neu': 0.733, 'pos': 0.181, 'compound': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Sentiment analysis each chapter\n",
    "for nr, chapter in enumerate(chapters):\n",
    "    scores = analyzer.polarity_scores(chapter)\n",
    "    print(nr + 1, scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
